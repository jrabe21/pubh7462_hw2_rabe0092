---
title: "PUBH 7462 Homework 2"
author: "Jack Rabe"
date: "2/9/2022"
output: 
  github_document:
    toc: true
    toc_depth: 3
---

```{r setup, include=FALSE}
#Load all the good stuff
library(tidyverse)
library(DataExplorer)
library(kableExtra)
library(gt)

#Working directory for .RMD
knitr::opts_knit$set(echo = TRUE,
                     root.dir = rprojroot::find_rstudio_root_file())

#Controlling figure output in markdown
knitr::opts_chunk$set(
#  fig.height =   
  fig.width = 6,
#  fig.asp = .5,
  out.width = "90%",
#  out.height = 
 fig.align = "center",
  cache = FALSE,
  echo  = TRUE
)

#Set Themes for ggplot2 - centers title and legend at bottom by default and edit background
theme_set(theme(plot.title = element_text(hjust = 0.5),
                legend.position = "bottom", 
                panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(),
                panel.background = element_blank(), 
                axis.line = element_line(colour = "black"))
)


#Set Scientific notation output and decimal places for knitr
options(scipen = 999)
options(digits = 4)
```


# Problem 3. BRFSS SMART 2002-2010

## 3.1 Data Exploration and Cleaning

```{r}
#read data with relative path
brfss.df <- read.csv(file = "./data/brfss_smart_2010.csv", header = TRUE) %>% 
  as_tibble()
```


```{r, include=FALSE}
#use dataExplorer to do some basic EDA
introduce(brfss.df) 
plot_intro(brfss.df)
plot_missing(brfss.df)
plot_str(brfss.df)
```



```{r, warning=FALSE, results='hide'}
#tidy time
tidy.brfss.df <- brfss.df %>% 
  janitor::clean_names() %>%  #clean up variable names
  filter(topic == "Overall Health") %>% #only retain rows where topic is overall health
  separate(col = "locationdesc",
           sep = "-",
           into = c("state", "county")) %>% #separate column into two distinct variables, "state" and "county"
  select(year, state, county, response, sample_size, data_value) %>% #only retain some of the columns for working with data
  mutate(
    year = as.numeric(year),
    county = str_remove(county, "County"),  #remove county from each data entry
    response = as.factor(response) %>% 
      fct_relevel("Poor", "Fair", "Good", "Very good"), #relevel from alphabetical to poor - excellent scale
  ) %>% 
  rename(health_cond = response,
         prop_response = data_value) %>% 
  arrange(year, state, county, health_cond)

#check that it all looks good
str(tidy.brfss.df)
```


## 3.2 Data Description

*Case definition*: Each observation in the retained **BRFSS** data set represents the number of responses, within a specific United States county and over a single year, that rated their health in a certain category along a scale of "poor" to "excellent." Each recorded response comes from adults in the United States who were surveyed over the phone by the Center for Disease Control and asked how they would rate their general health condition.

There are `r nrow(tidy.brfss.df)` observations in the filtered **BRFSS** data set with `r ncol(tidy.brfss.df)` variables.


The variables are as follows:

- *year* of course refers to the year (`r min(tidy.brfss.df$year)` to `r max(tidy.brfss.df$year)`) of penguin being measured

- *state* refers to the US state the surveys were conducted in for each observation

- *county* refers to the county the surveys were conducted in

- *health_cond* refers to the overall health condition (`r levels(tidy.brfss.df$health_cond)`) that people could respond with when asked how they would rate their general health

- *sample_size* refers to the number of responses recorded for a specific rating/condition (e.g. excellent) for that US county during that year's survey.

- *prop_response* refers to the proportion, or more accurately, percent of responses that rated themselves as a specific condition out of the total number of survey responses.


## 3.3 Do Data Science

### 3.3.1 In the year 2004, which states were observed at 6 locations?

```{r}
tidy.brfss.df %>% 
  filter(year == 2004) %>% #filter to only 2004
  group_by(state) %>% 
  summarise(unique_locs = n_distinct(county)) %>% #new variable tallying number of unique county locations observed in each state
  filter(unique_locs == 6) %>% #filter by states that observed 6 unique county locations in 2004
  rename(
    "State" = "state",
    "Locations Observed" = "unique_locs"
  ) %>% 
  gt() %>% 
  tab_header("States that were observed at 6 different locations in 2004")
  
```



### 3.3.2 Make a “spaghetti plot” that shows the number of observed locations in each state from 2002 to 2010. Which state has the highest mean number of locations over this period?


```{r}
tidy.brfss.df %>% 
  group_by(year, state) %>% 
  summarise(unique_locs = n_distinct(county)) %>% #new variable tallying number of unique county locations observed in each state
  
  ggplot(aes(x = year, 
             y = unique_locs, 
             color =  fct_reorder(state, unique_locs, .fun = mean, .desc = TRUE))
         ) +
  geom_line(size = 1) +
  scale_color_viridis_d("State") +
  labs(
    x = "Year",
    y = "Locations Observed",
    title = "Locations Observed in Each State from 2002 - 2010"
  )
```


The state with the highest mean number of locations observed each year from 2002 - 2010 is New Jersey (NJ) while the lowest is West Virginia (WV). It appears there may be some connection between mean number of locations observed in each state with how rural those states are. It appears that states with low population density tend to have fewer locations observed than states with higher population density.

For the most part, trends appear to be quite stable over time across all states with a trend towards gradually increasing the number of locations observed in each state. This trend has also led to more variability across states in how many locations were observed each year. For instance, in 2002 all states recorded fewer than 10 locations observed, with many recording less than around 6. However, by 2010, that changed quite a bit, with many states recording more than around 6 locations and a handful greater than 10 locations. One state even recorded close to 20 locations while another recorded around 40 locations in 2007 and 2010.


### 3.3.3 Make a table showing, for the years 2002, 2006, and 2010, the mean and standard deviation of sample size and proportion of Excellent, Good, and Poor responses across locations in MN. 


